{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxPpmHsLBNqA"
      },
      "outputs": [],
      "source": [
        "# installation\n",
        "!pip install transformers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from google.colab import files\n",
        "from pathlib import Path\n",
        "import json\n",
        "from transformers import pipeline\n",
        "from dataclasses import dataclass"
      ],
      "metadata": {
        "id": "ouszbnOjBZiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !!!!!! huggingface login required to use llama model (ADD TOKEN AFTER `--token`) !!!!!!\n",
        "!huggingface-cli login --token"
      ],
      "metadata": {
        "id": "Ry6vHqu5SRN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# settings\n",
        "checkpoint = 'meta-llama/Llama-3.2-1B-Instruct'"
      ],
      "metadata": {
        "id": "qOXXNOCvRnLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup text generation pipeline\n",
        "pipe = pipeline(\"text-generation\", model = checkpoint)"
      ],
      "metadata": {
        "id": "fyRND-gZS3Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utilities\n",
        "def save_json(data, file_name):\n",
        "    with open(file_name, 'w') as f:\n",
        "        json.dump(data, f)\n",
        "\n",
        "def load_json(file_name):\n",
        "    with open(file_name, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def get_response(raw_output):\n",
        "  return raw_output[0]['generated_text'][-1]['content']"
      ],
      "metadata": {
        "id": "Oh61vFsSRk4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !!!! LOAD ALL FILES IN `ocr_results/` directory` !!!!!\n",
        "ocr_extractions = files.upload()\n",
        "ocr_extractions = [load_json(el) for el in ocr_extractions.keys()]"
      ],
      "metadata": {
        "id": "fj-An8vmYsET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Template for schema inference\n",
        "@dataclass\n",
        "class Template:\n",
        "  ocr_extractions: list\n",
        "\n",
        "  def ocr_to_doc(self, ocr_extraction):\n",
        "    return '\\n'.join(ocr_extraction)\n",
        "\n",
        "  def label_document(self, doc, num):\n",
        "    return f'Document {num}:\\n\\n{doc}'\n",
        "\n",
        "  def concat_docs(self, docs):\n",
        "    docs = [self.label_document(doc, i+1) for i, doc in enumerate(docs)]\n",
        "    return '\\n---\\n'.join(docs)\n",
        "\n",
        "  def ocr_to_string(self):\n",
        "    docs = [self.ocr_to_doc(el) for el in self.ocr_extractions]\n",
        "    string = self.concat_docs(docs)\n",
        "    return string\n",
        "\n",
        "  def prompt(self):\n",
        "    string = self.ocr_to_string()\n",
        "\n",
        "    system = '''The following is a document containing one or more emails.\n",
        "\n",
        "Your task is to read the following emails and infer a JSON schema that will capture the structure that is common to emails in general.\n",
        "\n",
        "There may be more than one email in the text, so make sure the schema can handle an arbitrary number of emails. It is very important to refrain from repeating keys.\n",
        "\n",
        "Remember, your task is to infer a schema, not to fill it out with details from an email.\n",
        "\n",
        "Now extract the schema and output only the JSON object below with no additional filler text.\n",
        "\n",
        "JSON:'''\n",
        "\n",
        "    #system = \"The following is a document containing one or more emails.\\n\\nWe want to extract structured information from emails in the form of a JSON object. Your task is read the following emails and infer a schema that will capture the structure that is common to emails in general.\\n\\nThere may be more than one email in the text, so make sure the schema can handle an arbitrary number of emails. The schema should heavily prioritize conciseness, avoiding repeat keys, but allowing for multiple entries.\\n\\nPlease format the schema in a JSON object.\"\n",
        "    user = string\n",
        "\n",
        "    messages = [\n",
        "      {\"role\": \"system\", \"content\": system},\n",
        "      {\"role\": \"user\", \"content\": user},\n",
        "    ]\n",
        "\n",
        "    return messages\n",
        "\n",
        "\n",
        "  def generate(self, pipe):\n",
        "    messages = self.prompt()\n",
        "    return pipe(messages,\n",
        "                max_new_tokens=3000,\n",
        "                do_sample = False,\n",
        "                repetition_penalty = 1.05)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BK3MemcaiDzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiates prompter with a few sample emails\n",
        "template = Template(ocr_extractions)"
      ],
      "metadata": {
        "id": "dOegquMSRo07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generates template\n",
        "gen = template.generate(pipe)"
      ],
      "metadata": {
        "id": "KIVqy9_Cm8tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# discards extraneous output\n",
        "schema = get_response(gen)"
      ],
      "metadata": {
        "id": "AAIDTq95qw5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saves schema\n",
        "save_json(schema, 'schema.json')"
      ],
      "metadata": {
        "id": "-j8FicogPoJM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
